{
  "nbformat_minor": 1,
  "metadata": {
    "language_info": {
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "name": "python",
      "mimetype": "text/x-python",
      "version": "3.6.1",
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "f7f21baf4957f5dce2b6a5e2d60be9b66b153609",
        "_cell_guid": "3e9366e6-e996-4216-97dc-7e44d8cf4a19"
      },
      "source": [
        "# Importing the libraries\n",
        "\n",
        "# remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('../input/train.csv')\n",
        "testSet=pd.read_csv('../input/test.csv')\n",
        "print(\"data set info\",\"*\"*40)\n",
        "dataset.info()\n",
        "\n",
        "print(\"test set info\",\"*\"*40)\n",
        "testSet.info()\n",
        "print(\"*\"*40)\n",
        "\n",
        "\n",
        "#descriptive statistics\n",
        "#distribution of numerical feature values across the samples\n",
        "dataset.describe()\n",
        "print(\"*\"*40)\n",
        "\n",
        "list(dataset) #get column namess \n",
        "\n",
        "#get details about catagorical variables\n",
        "dataset.describe(include=['O'])\n",
        "\n",
        "#Select the columns to use in the model \n",
        "dataset = dataset.iloc[:,[0,1,2,4,5,9]]\n",
        "testSet = testSet.iloc[:,[0,1,3,4,8]]\n",
        "\n",
        "\n",
        "#X must be a data set to view this \n",
        "print(dataset['PassengerId'].isnull().sum())\n",
        "print(dataset['Pclass'].isnull().sum())\n",
        "print(dataset['Sex'].isnull().sum())\n",
        "print(dataset['Age'].isnull().sum())\n",
        "print(dataset['Fare'].isnull().sum())\n",
        "\n",
        "print(\"*\"*40)\n",
        "#test set check null \n",
        "print(testSet['PassengerId'].isnull().sum())\n",
        "print(testSet['Pclass'].isnull().sum())\n",
        "print(testSet['Sex'].isnull().sum())\n",
        "print(testSet['Age'].isnull().sum())\n",
        "print(testSet['Fare'].isnull().sum())\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "49846aea3930cc401078910e907a0dea16ba17f4"
      },
      "source": [
        "\n",
        "# Taking care of missing data in Age\n",
        "from sklearn.preprocessing import Imputer\n",
        "imputer = Imputer(missing_values=\"NaN\", strategy = 'mean', axis = 0)\n",
        "imputer = imputer.fit(dataset.iloc[:,4:5].values)\n",
        "dataset.iloc[:,4:5]= imputer.transform(dataset.iloc[:,4:5].values)\n",
        "\n",
        "imputer2 = Imputer(missing_values=\"NaN\", strategy = 'mean', axis = 0)\n",
        "imputer = imputer2.fit(testSet.iloc[:,3:5].values)\n",
        "testSet.iloc[:,3:5]= imputer2.transform(testSet.iloc[:,3:5].values)\n",
        "\n",
        "\n",
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder_X = LabelEncoder()\n",
        "dataset.iloc[:,3:4] = labelencoder_X.fit_transform(dataset.iloc[:,3:4].values)\n",
        "\n",
        "\n",
        "labelencoder_X1 = LabelEncoder()\n",
        "testSet.iloc[:,2:3] = labelencoder_X1.fit_transform(testSet.iloc[:,2:3].values)\n",
        "\n",
        "X = dataset.iloc[:,[0,2,3,4,5]].values\n",
        "y = dataset.iloc[:,1].values\n",
        "\n",
        "\n",
        "#observe how survival reflects with the variables\n",
        "#No survivours vs Age \n",
        "gan = sns.FacetGrid(dataset, col='Survived')\n",
        "gan.map(plt.hist, 'Age', bins=10)\n",
        "\n",
        "#No survivours vs Age and class\n",
        "grid = sns.FacetGrid(dataset, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n",
        "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
        "grid.add_legend();\n",
        "\n",
        "\n",
        "list(dataset)\n",
        "\n",
        "#No survivors vs Sex \n",
        "\n",
        "gan = sns.FacetGrid(dataset, col='Survived')\n",
        "gan.map(plt.hist, 'Sex', bins=10)\n",
        "\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "7e69b64a8e8f6208cbd8426b51cb59490cbec3ba"
      },
      "source": [
        "\n",
        "\"\"\"# Splitting the dataset into the Training set and Test set\n",
        "#from sklearn.cross_validation import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0, random_state = 0)\n",
        "\"\"\"\n",
        "X_train=X\n",
        "y_train=y\n",
        "X_test=testSet.iloc[:,:].values\n",
        "\n",
        "\n",
        " #Fitting Random Forest Regression to the Training set\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "Regressor = RandomForestRegressor(n_estimators = 100,oob_score=True, random_state = 0)\n",
        "Regressor.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Check the importance of variables\n",
        "Regressor.feature_importances_\n",
        "F_importance=pd.Series(Regressor.feature_importances_,index=(dataset.iloc[:,[0,2,3,4,5]]).columns)\n",
        "F_importance.plot(kind=\"barh\" , figsize=(7,6))\n",
        "\n",
        "\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "70063cbe71f12ba1fcb67e3fc4d8d963da0b8dc8"
      },
      "source": [
        "\n",
        " #Fitting Random Forest Classification to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators =195, criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "\"\"\"# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Applying k-Fold Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "accuracies.mean()\n",
        "print(\"Accuracy =\",accuracies.mean())\n",
        "\n",
        "\n",
        "#grid search hyper parameter tuning\n",
        "\"\"\"\n",
        "# Applying Grid Search to find the best model and the best parameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = [{'n_estimators': [195,196,197]}]\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 10,\n",
        "                           n_jobs = -1)\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "best_accuracy = grid_search.best_score_\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "got accuracy of 0.830212234707for n_estimator=195\n",
        "\"\"\"\n",
        "print(y_pred)"
      ],
      "outputs": []
    }
  ]
}